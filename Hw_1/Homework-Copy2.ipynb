{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "technological-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from librosa import display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm\n",
    "import IPython.display as ipd\n",
    "import scipy as sp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "interstate-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 60.16it/s]\n"
     ]
    }
   ],
   "source": [
    "classes = ['Distortion', 'Tremolo', 'NoFX']\n",
    "n_centroids = 173\n",
    "dict_train_features = {'Distortion': [], 'Tremolo': [], 'NoFX': []}\n",
    "\n",
    "for c in tqdm(classes):\n",
    "    train_root = 'inputs/{}/training/'.format(c)\n",
    "    class_train_files = [f for f in os.listdir(train_root) if f.endswith('.wav')]\n",
    "    n_train_samples = len(class_train_files)\n",
    "    \n",
    "    train_features = np.zeros((n_train_samples, n_centroids))\n",
    "    for index, f in enumerate(class_train_files):\n",
    "        audio, fs = librosa.load(os.path.join(train_root, f), sr=None)\n",
    "        audio = audio/np.max(np.absolute(audio))\n",
    "        centroids = librosa.feature.rms(audio, frame_length=1024, hop_length=512)\n",
    "        train_features[index] = centroids\n",
    "        \n",
    "\n",
    "    dict_train_features[c] = train_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "married-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cents in dict_train_features[\"Distortion\"]:\n",
    "    #fig = plt.figure(figsize=(16, 6))\n",
    "    #plt.plot(np.arange(n_centroids), np.transpose(cents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bronze-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cents in dict_train_features[\"Tremolo\"]:\n",
    "    #fig = plt.figure(figsize=(16, 6))\n",
    "    #plt.plot(np.arange(n_centroids), np.transpose(cents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "independent-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 75.19it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_test_features = {'Distortion': [], 'Tremolo': [], 'NoFX': []}\n",
    "\n",
    "for c in tqdm(classes):\n",
    "    test_root = 'inputs/{}/test/'.format(c)\n",
    "    class_test_files = [f for f in os.listdir(test_root) if f.endswith('.wav')]\n",
    "    n_test_samples = len(class_test_files)\n",
    "    \n",
    "    test_features = np.zeros((n_test_samples, n_centroids))\n",
    "    for index, f in enumerate(class_test_files):\n",
    "        audio, fs = librosa.load(os.path.join(test_root, f), sr=None)\n",
    "        audio = audio/np.max(np.absolute(audio))\n",
    "        centroids = librosa.feature.rms(audio, frame_length=1024, hop_length=512)\n",
    "        test_features[index, :] = centroids\n",
    "        \n",
    "    dict_test_features[c] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "social-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = 'Distortion'\n",
    "class_1 = 'Tremolo'\n",
    "\n",
    "X_train_0 = dict_train_features[class_0]\n",
    "X_train_1 = dict_train_features[class_1]\n",
    "\n",
    "X_train = np.concatenate((X_train_0, X_train_1), axis=0)\n",
    "\n",
    "y_train_0 = np.zeros((X_train_0.shape[0],))\n",
    "y_train_1 = np.ones((X_train_1.shape[0],))\n",
    "\n",
    "y_train = np.concatenate((y_train_0, y_train_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "chief-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0 = dict_test_features[class_0]\n",
    "X_test_1 = dict_test_features[class_1]\n",
    "\n",
    "X_test = np.concatenate((X_test_0, X_test_1), axis=0)\n",
    "\n",
    "y_test_0 = np.zeros((X_test_0.shape[0],))\n",
    "y_test_1 = np.ones((X_test_1.shape[0],))\n",
    "\n",
    "y_test = np.concatenate((y_test_0, y_test_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cardiac-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_max = np.max(X_train, axis=0)\n",
    "feat_min = np.min(X_train, axis=0)\n",
    "X_train_normalized = (X_train - feat_min) / (feat_max - feat_min)\n",
    "X_test_normalized = (X_test - feat_min) / (feat_max - feat_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-being",
   "metadata": {},
   "source": [
    "# Weighted Support Vector Machine\n",
    "\n",
    "Specifically, each example in the training dataset has its own penalty term (C value) used in the calculation for the margin when fitting the SVM model. The value of an example’s C-value can be calculated as a weighting of the global C-value, where the weight is defined proportional to the class distribution.\n",
    "\n",
    "C_i = weight_i * C\n",
    "\n",
    "A larger weighting can be used for the minority class, allowing the margin to be softer, whereas a smaller weighting can be used for the majority class, forcing the margin to be harder and preventing misclassified examples.\n",
    "\n",
    "Small Weight: Smaller C value, larger penalty for misclassified examples.\n",
    "\n",
    "Larger Weight: Larger C value, smaller penalty for misclassified examples.\n",
    "\n",
    "This has the effect of encouraging the margin to contain the majority class with less flexibility, but allow the minority class to be flexible with misclassification of majority class examples onto the minority class side if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "brave-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_parameters={\n",
    "    'C': 100, \n",
    "    '''\n",
    "    C stands for the regularization parameter that controls the trade-off between maximizing \n",
    "    the separation margin between classes and minimizing the number of misclassified instances.\n",
    "    C determines the number and severity of the violations to the margin (and to the hyperplane) that we will tolerate\n",
    "    '''\n",
    "    'kernel': 'rbf',\n",
    "    #'class_weight' : 'balanced'\n",
    "    '''By default, each class has the same weighting, which means that the softness of the margin is symmetrical.'''\n",
    "}\n",
    "\n",
    "clf = sklearn.svm.SVC(**SVM_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "electoral-poetry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "victorian-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(gt_labels, predicted_labels):\n",
    "    TP = np.sum(np.logical_and(predicted_labels == 1, gt_labels == 1))\n",
    "    FP = np.sum(np.logical_and(predicted_labels == 1, gt_labels == 0))\n",
    "    TN = np.sum(np.logical_and(predicted_labels == 0, gt_labels == 0))\n",
    "    FN = np.sum(np.logical_and(predicted_labels == 0, gt_labels == 1))\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Results : \\n accuracy = {} \\n precision = {} \\n recall = {} \\n F1 score = {}\".format(\n",
    "        accuracy, precision, recall, F1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "rotary-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results : \n",
      " accuracy = 1.0 \n",
      " precision = 1.0 \n",
      " recall = 1.0 \n",
      " F1 score = 1.0\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = clf.predict(X_test_normalized)\n",
    "\n",
    "compute_metrics(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "allied-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = 'Distortion'\n",
    "class_1 = 'Tremolo'\n",
    "class_2 = 'NoFX'\n",
    "\n",
    "X_train_0 = dict_train_features[class_0]\n",
    "X_train_1 = dict_train_features[class_1]\n",
    "X_train_2 = dict_train_features[class_2]\n",
    "\n",
    "y_train_0 = np.zeros((X_train_0.shape[0],))\n",
    "y_train_1 = np.ones((X_train_1.shape[0],))\n",
    "y_train_2 = np.ones((X_train_2.shape[0],))*2\n",
    "\n",
    "#y_train = np.concatenate((y_train_class_0, y_train_class_1, y_train_class_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "precious-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0 = dict_test_features[class_0]\n",
    "X_test_1 = dict_test_features[class_1]\n",
    "X_test_2 = dict_test_features[class_2]\n",
    "\n",
    "\n",
    "y_test_0 = np.zeros((X_test_0.shape[0],))\n",
    "y_test_1 = np.ones((X_test_1.shape[0],))\n",
    "y_test_2 = np.ones((X_test_2.shape[0],))*2\n",
    "\n",
    "y_test_mc = np.concatenate((y_test_0, y_test_1, y_test_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "colored-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_max = np.max(np.concatenate((X_train_0, X_train_1, X_train_2), axis=0), axis=0)\n",
    "feat_min = np.min(np.concatenate((X_train_0, X_train_1, X_train_2), axis=0), axis=0)\n",
    "\n",
    "X_train_0_normalized = (X_train_0 - feat_min) / (feat_max - feat_min)\n",
    "X_train_1_normalized = (X_train_1 - feat_min) / (feat_max - feat_min)\n",
    "X_train_2_normalized = (X_train_2 - feat_min) / (feat_max - feat_min)\n",
    "\n",
    "X_test_0_normalized = (X_test_0 - feat_min) / (feat_max - feat_min)\n",
    "X_test_1_normalized = (X_test_1 - feat_min) / (feat_max - feat_min)\n",
    "X_test_2_normalized = (X_test_2 - feat_min) / (feat_max - feat_min)\n",
    "\n",
    "X_test_mc_normalized = np.concatenate((X_test_0_normalized, X_test_1_normalized, X_test_2_normalized), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "patent-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_parameters={\n",
    "    'C': 100,\n",
    "    'kernel': 'rbf',\n",
    "    #'class_weight' : 'balanced'\n",
    "}\n",
    "\n",
    "clf_01 = sklearn.svm.SVC(**SVM_parameters, probability=True)\n",
    "clf_02 = sklearn.svm.SVC(**SVM_parameters, probability=True)\n",
    "clf_12 = sklearn.svm.SVC(**SVM_parameters, probability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "vital-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, probability=True)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_01.fit(np.concatenate((X_train_0_normalized, X_train_1_normalized), axis=0), \n",
    "           np.concatenate((y_train_0, y_train_1), axis=0))\n",
    "           \n",
    "clf_02.fit(np.concatenate((X_train_0_normalized, X_train_2_normalized), axis=0), \n",
    "           np.concatenate((y_train_0, y_train_2), axis=0))\n",
    "\n",
    "clf_12.fit(np.concatenate((X_train_1_normalized, X_train_2_normalized), axis=0), \n",
    "           np.concatenate((y_train_1, y_train_2), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cosmetic-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_01 = clf_01.predict(X_test_mc_normalized).reshape(-1, 1)\n",
    "y_test_predicted_02 = clf_02.predict(X_test_mc_normalized).reshape(-1, 1)\n",
    "y_test_predicted_12 = clf_12.predict(X_test_mc_normalized).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "remarkable-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_mc = np.concatenate((y_test_predicted_01, y_test_predicted_02, y_test_predicted_12), axis=1)\n",
    "y_test_predicted_mc = np.array(y_test_predicted_mc, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "individual-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_mv = np.zeros((y_test_predicted_mc.shape[0],))\n",
    "for i, e in enumerate(y_test_predicted_mc):\n",
    "    y_test_predicted_mv[i] = np.bincount(e).argmax() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "existing-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cm_multiclass(gt, predicted):\n",
    "    classes = np.unique(gt)\n",
    "    \n",
    "    CM = np.zeros((len(classes), len(classes)))\n",
    "    \n",
    "    for i in np.arange(len(classes)):\n",
    "        pred_class = predicted[gt==i]\n",
    "        \n",
    "        for j in np.arange(len(pred_class)):\n",
    "            CM[i, int(pred_class[j])] = CM[i, int(pred_class[j])] + 1 \n",
    "    print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "arbitrary-holocaust",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  0.  0.]\n",
      " [ 0.  7.  3.]\n",
      " [ 0.  5.  5.]]\n"
     ]
    }
   ],
   "source": [
    "compute_cm_multiclass(y_test_mc, y_test_predicted_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-montana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
